{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marevalojaimes/Arevalo_DSPN_S25/blob/main/Exercise10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2W919d2ZXp7"
      },
      "source": [
        "# Exercise 10: Mixed effects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading and formatting the data 1/1\n",
        "2. Model fitting 4/4\n",
        "3. Model assessment 4/4\n",
        "4. Reflection 1/1"
      ],
      "metadata": {
        "id": "SLkCYuP9TqPo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nOzVhyZXqK"
      },
      "source": [
        "This homework assignment is designed to give you practice fitting and interpreting mixed effects models.\n",
        "\n",
        "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again.\n",
        "\n",
        "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file.\n",
        "\n",
        "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsyBTB6ZXqN"
      },
      "source": [
        "---\n",
        "## 1. Loading and formatting the data (1 point)\n",
        "\n",
        "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**.\n",
        "\n",
        "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnBVazYfZXqP",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "f462991f-654f-474b-c504-24269505c487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22mNew names:\n",
            "\u001b[36m•\u001b[39m `` -> `...1`\n",
            "\u001b[1mRows: \u001b[22m\u001b[34m74869\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m9\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m (1): D_Word\n",
            "\u001b[32mdbl\u001b[39m (6): ...1, Sub_ID, Trial, Type, D_Zscore, Correct\n",
            "\u001b[32mnum\u001b[39m (1): D_RT\n",
            "\u001b[33mlgl\u001b[39m (1): Outlier\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "\u001b[1mRows: \u001b[22m\u001b[34m30959\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m (1): Word\n",
            "\u001b[32mdbl\u001b[39m (3): Occurrences, Length, Log_Freq_HAL\n",
            "\u001b[32mnum\u001b[39m (1): Freq_HAL\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 5</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>Occurrences</th><th scope=col>Word</th><th scope=col>Length</th><th scope=col>Freq_HAL</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>1</td><td>synergistic</td><td>11</td><td> 284</td><td>5.649</td></tr>\n",
              "\t<tr><td>1</td><td>synonymous </td><td>10</td><td> 951</td><td>6.858</td></tr>\n",
              "\t<tr><td>1</td><td>syntactical</td><td>11</td><td> 114</td><td>4.736</td></tr>\n",
              "\t<tr><td>1</td><td>synthesis  </td><td> 9</td><td>6742</td><td>8.816</td></tr>\n",
              "\t<tr><td>1</td><td>synthesized</td><td>11</td><td>2709</td><td>7.904</td></tr>\n",
              "\t<tr><td>1</td><td>synthesizer</td><td>11</td><td>1390</td><td>7.237</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 5\n\n| Occurrences &lt;dbl&gt; | Word &lt;chr&gt; | Length &lt;dbl&gt; | Freq_HAL &lt;dbl&gt; | Log_Freq_HAL &lt;dbl&gt; |\n|---|---|---|---|---|\n| 1 | synergistic | 11 |  284 | 5.649 |\n| 1 | synonymous  | 10 |  951 | 6.858 |\n| 1 | syntactical | 11 |  114 | 4.736 |\n| 1 | synthesis   |  9 | 6742 | 8.816 |\n| 1 | synthesized | 11 | 2709 | 7.904 |\n| 1 | synthesizer | 11 | 1390 | 7.237 |\n\n",
            "text/latex": "A tibble: 6 × 5\n\\begin{tabular}{lllll}\n Occurrences & Word & Length & Freq\\_HAL & Log\\_Freq\\_HAL\\\\\n <dbl> & <chr> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t 1 & synergistic & 11 &  284 & 5.649\\\\\n\t 1 & synonymous  & 10 &  951 & 6.858\\\\\n\t 1 & syntactical & 11 &  114 & 4.736\\\\\n\t 1 & synthesis   &  9 & 6742 & 8.816\\\\\n\t 1 & synthesized & 11 & 2709 & 7.904\\\\\n\t 1 & synthesizer & 11 & 1390 & 7.237\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Occurrences Word        Length Freq_HAL Log_Freq_HAL\n",
              "1 1           synergistic 11      284     5.649       \n",
              "2 1           synonymous  10      951     6.858       \n",
              "3 1           syntactical 11      114     4.736       \n",
              "4 1           synthesis    9     6742     8.816       \n",
              "5 1           synthesized 11     2709     7.904       \n",
              "6 1           synthesizer 11     1390     7.237       "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 11</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>...1</th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th><th scope=col>Correct</th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>1</td><td>157</td><td>1</td><td>1</td><td> 710</td><td>browse     </td><td>FALSE</td><td>-0.437</td><td>1</td><td> 6</td><td>8.856</td></tr>\n",
              "\t<tr><td>2</td><td> 67</td><td>1</td><td>1</td><td>1094</td><td>refrigerant</td><td>FALSE</td><td> 0.825</td><td>1</td><td>11</td><td>4.644</td></tr>\n",
              "\t<tr><td>3</td><td>120</td><td>1</td><td>1</td><td> 587</td><td>gaining    </td><td>FALSE</td><td>-0.645</td><td>1</td><td> 7</td><td>8.304</td></tr>\n",
              "\t<tr><td>4</td><td> 21</td><td>1</td><td>1</td><td> 984</td><td>cheerless  </td><td>FALSE</td><td> 0.025</td><td>1</td><td> 9</td><td>2.639</td></tr>\n",
              "\t<tr><td>5</td><td>236</td><td>1</td><td>1</td><td> 577</td><td>pattered   </td><td>FALSE</td><td>-0.763</td><td>1</td><td> 8</td><td>1.386</td></tr>\n",
              "\t<tr><td>6</td><td>236</td><td>2</td><td>1</td><td> 715</td><td>conjures   </td><td>FALSE</td><td>-0.364</td><td>1</td><td> 8</td><td>5.268</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 11\n\n| ...1 &lt;dbl&gt; | Sub_ID &lt;dbl&gt; | Trial &lt;dbl&gt; | Type &lt;dbl&gt; | D_RT &lt;dbl&gt; | D_Word &lt;chr&gt; | Outlier &lt;lgl&gt; | D_Zscore &lt;dbl&gt; | Correct &lt;dbl&gt; | Length &lt;dbl&gt; | Log_Freq_HAL &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 157 | 1 | 1 |  710 | browse      | FALSE | -0.437 | 1 |  6 | 8.856 |\n| 2 |  67 | 1 | 1 | 1094 | refrigerant | FALSE |  0.825 | 1 | 11 | 4.644 |\n| 3 | 120 | 1 | 1 |  587 | gaining     | FALSE | -0.645 | 1 |  7 | 8.304 |\n| 4 |  21 | 1 | 1 |  984 | cheerless   | FALSE |  0.025 | 1 |  9 | 2.639 |\n| 5 | 236 | 1 | 1 |  577 | pattered    | FALSE | -0.763 | 1 |  8 | 1.386 |\n| 6 | 236 | 2 | 1 |  715 | conjures    | FALSE | -0.364 | 1 |  8 | 5.268 |\n\n",
            "text/latex": "A tibble: 6 × 11\n\\begin{tabular}{lllllllllll}\n ...1 & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore & Correct & Length & Log\\_Freq\\_HAL\\\\\n <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <lgl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t 1 & 157 & 1 & 1 &  710 & browse      & FALSE & -0.437 & 1 &  6 & 8.856\\\\\n\t 2 &  67 & 1 & 1 & 1094 & refrigerant & FALSE &  0.825 & 1 & 11 & 4.644\\\\\n\t 3 & 120 & 1 & 1 &  587 & gaining     & FALSE & -0.645 & 1 &  7 & 8.304\\\\\n\t 4 &  21 & 1 & 1 &  984 & cheerless   & FALSE &  0.025 & 1 &  9 & 2.639\\\\\n\t 5 & 236 & 1 & 1 &  577 & pattered    & FALSE & -0.763 & 1 &  8 & 1.386\\\\\n\t 6 & 236 & 2 & 1 &  715 & conjures    & FALSE & -0.364 & 1 &  8 & 5.268\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  ...1 Sub_ID Trial Type D_RT D_Word      Outlier D_Zscore Correct Length\n",
              "1 1    157    1     1     710 browse      FALSE   -0.437   1        6    \n",
              "2 2     67    1     1    1094 refrigerant FALSE    0.825   1       11    \n",
              "3 3    120    1     1     587 gaining     FALSE   -0.645   1        7    \n",
              "4 4     21    1     1     984 cheerless   FALSE    0.025   1        9    \n",
              "5 5    236    1     1     577 pattered    FALSE   -0.763   1        8    \n",
              "6 6    236    2     1     715 conjures    FALSE   -0.364   1        8    \n",
              "  Log_Freq_HAL\n",
              "1 8.856       \n",
              "2 4.644       \n",
              "3 8.304       \n",
              "4 2.639       \n",
              "5 1.386       \n",
              "6 5.268       "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "library(readr)\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "lexical_inc_data <- read_csv(\"https://raw.githubusercontent.com/marevalojaimes/Data_ScienceCMU/refs/heads/master/Homework%20datasets/lexDat/LexicalData_withIncorrect.csv\")\n",
        "items_data <- read_csv (\"https://raw.githubusercontent.com/marevalojaimes/Data_ScienceCMU/refs/heads/master/Homework%20datasets/lexDat/Items.csv\")\n",
        "lexical_inc_data$D_RT<- as.numeric(gsub(\",\" , \"\", lexical_inc_data$D_RT))\n",
        "\n",
        "items <- items_data %>%\n",
        "  select (Word,Length,Log_Freq_HAL) %>%\n",
        "  rename(D_Word = Word)\n",
        "\n",
        "Lexical_merged <- lexical_inc_data %>%\n",
        "  left_join(items, by = \"D_Word\") %>%\n",
        "  drop_na()\n",
        "\n",
        "head (Lexical_merged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXy81Viishk1"
      },
      "source": [
        "---\n",
        "## 2. Model fitting (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7_gEgkbzFtU"
      },
      "source": [
        "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIOIg-GRz4rN",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "b50081fa-be9b-4d53-a503-a83bd749ecaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = D_RT ~ Log_Freq_HAL * Length, data = Lexical_merged)\n",
              "\n",
              "Residuals:\n",
              "    Min      1Q  Median      3Q     Max \n",
              "-1128.3  -217.6   -94.0    94.2  3317.2 \n",
              "\n",
              "Coefficients:\n",
              "                    Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)         650.3764    14.3247  45.403  < 2e-16 ***\n",
              "Log_Freq_HAL        -10.0802     1.9643  -5.132 2.88e-07 ***\n",
              "Length               45.5806     1.5992  28.503  < 2e-16 ***\n",
              "Log_Freq_HAL:Length  -2.6346     0.2345 -11.236  < 2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 384.2 on 70585 degrees of freedom\n",
              "Multiple R-squared:  0.08867,\tAdjusted R-squared:  0.08863 \n",
              "F-statistic:  2289 on 3 and 70585 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model1 =lm(D_RT ~ Log_Freq_HAL * Length  , data = Lexical_merged)\n",
        "summary(model1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbeg_JrS3mwU"
      },
      "source": [
        "Now, install `lme4` using `install.packages()` and then load the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSnvvb_re2O",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "6f09988b-8c0e-4fe2-c145-4bc2f4cf9c8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Rdpack’, ‘reformulas’, ‘RcppEigen’\n",
            "\n",
            "\n",
            "Loading required package: Matrix\n",
            "\n",
            "\n",
            "Attaching package: ‘Matrix’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:tidyr’:\n",
            "\n",
            "    expand, pack, unpack\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"lme4\")\n",
        "library(lme4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZJns7xr41nW"
      },
      "source": [
        "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kjwT0je57N7",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "226b6834-b4ab-4f1f-8799-611e4e65fa9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Linear mixed model fit by REML ['lmerMod']\n",
              "Formula: D_RT ~ Log_Freq_HAL * Length + (1 | Sub_ID)\n",
              "   Data: Lexical_merged\n",
              "\n",
              "REML criterion at convergence: 1012299\n",
              "\n",
              "Scaled residuals: \n",
              "    Min      1Q  Median      3Q     Max \n",
              "-4.2579 -0.5401 -0.1555  0.2986 11.0922 \n",
              "\n",
              "Random effects:\n",
              " Groups   Name        Variance Std.Dev.\n",
              " Sub_ID   (Intercept) 51061    226.0   \n",
              " Residual             97009    311.5   \n",
              "Number of obs: 70589, groups:  Sub_ID, 299\n",
              "\n",
              "Fixed effects:\n",
              "                    Estimate Std. Error t value\n",
              "(Intercept)         652.6262    17.4987  37.296\n",
              "Log_Freq_HAL        -11.0297     1.5960  -6.911\n",
              "Length               45.7392     1.2990  35.211\n",
              "Log_Freq_HAL:Length  -2.5742     0.1905 -13.514\n",
              "\n",
              "Correlation of Fixed Effects:\n",
              "            (Intr) Lg_F_HAL Length\n",
              "Log_Frq_HAL -0.621                \n",
              "Length      -0.635  0.913         \n",
              "Lg_Fr_HAL:L  0.561 -0.943   -0.919"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model2<-lmer(D_RT ~ Log_Freq_HAL * Length + (1| Sub_ID)  , data = Lexical_merged)\n",
        "summary(model2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb_ovk7JFGt"
      },
      "source": [
        "---\n",
        "## 3. Model assessment (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7B1Ux6RHGjy"
      },
      "source": [
        "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCi5gYOeHo6m"
      },
      "source": [
        "> The t-value of Log_Freq_Hal in the linear model (-5.13) is smaller compared to the mixed effect model (-6.91). Similarly, length follow this trend with a greater t-value in the mixed effects model (35.21) than in the fixed effects (28.50). Lastly, the interaction between lenght and frequency showed also a larger effect in the mixed model (-13.51) in contrast to the linear model(-11.23).   \n",
        "\n",
        "We can conclude that the mixed effect model has an overall better fit than the lineal model because it accounts for the subject variability, which allow us to make more accurate predictions of the outcome with our variables word lengh and frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukKG1AbGqXM"
      },
      "source": [
        "Use the Aikeke Information Criterion (AIC) to compare these two models. Which one is better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMDg8qb5FhJz",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "65a54205-3c94-4cd2-d8d6-a81463d16c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 1040519\n",
            "[1] 1012311\n",
            "[1] 28208.17\n"
          ]
        }
      ],
      "source": [
        "aic_lm <- AIC(model1)\n",
        "aic_mx <- AIC(model2)\n",
        "print(aic_lm)\n",
        "print(aic_mx)\n",
        "print(aic_lm-aic_mx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4oTfsYmIvYt"
      },
      "source": [
        "> There is a large difference between linear and mixed models (28208.17). Particularly, the mixed model has lower AIC which indicates, this model is better than the linear model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARF2PF2yLXkZ"
      },
      "source": [
        "---\n",
        "##  4. Reflection (1 point)\n",
        "\n",
        "What other random effects could be controlled for in this data set?\n",
        "\n",
        "> It would be important to control for whether the RT is affected by random effects of correct/incorrect responses. Also, I think trial type might be useful to explore because the effects of word lenght and frequency could vary across trials.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4MPECMmZXqe"
      },
      "source": [
        "**DUE:** 5pm EST, March 18, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GUofXN4BVy"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}